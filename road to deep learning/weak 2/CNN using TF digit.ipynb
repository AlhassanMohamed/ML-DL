{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (60000,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape , y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 28, 28), (10000,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape , y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train[0:5000]\n",
    "y_train = y_train[0:5000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5000, 28, 28), (5000,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape , y_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = x_test[0:1000]\n",
    "y_test = y_test[0:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1000, 28, 28), (1000,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape , y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train =x_train.reshape(5000, 28, 28, 1)\n",
    "x_test = x_test.reshape(1000,28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionary of target classes\n",
    "label_dict = {\n",
    " 0: 'zero',\n",
    " 1: 'one',\n",
    " 2: 'two',\n",
    " 3: 'three',\n",
    " 4: 'four',\n",
    " 5: 'five',\n",
    " 6: 'six',\n",
    " 7: 'seven',\n",
    " 8: 'eight',\n",
    " 9: 'nine',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'(Label: zero)')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=[5,5])\n",
    "\n",
    "# Display the first image in training data\n",
    "plt.subplot(121)\n",
    "\n",
    "curr_img = np.reshape(x_train[0], (28,28))\n",
    "curr_lbl = np.argmax(y_train[0])\n",
    "\n",
    "plt.imshow(curr_img)\n",
    "plt.title(\"(Label: \" + str(label_dict[curr_lbl]) + \")\")\n",
    "\n",
    "# Display the first image in testing data\n",
    "plt.subplot(122)\n",
    "curr_img = np.reshape(x_test[99,:], (28,28))\n",
    "curr_lbl = np.argmax(y_test[99])\n",
    "\n",
    "plt.imshow(curr_img, cmap='gray')\n",
    "plt.title(\"(Label: \" + str(label_dict[curr_lbl]) + \")\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_iters = 12\n",
    "learning_rate = 0.001 \n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST data input (img shape: 28*28)\n",
    "n_input = 28\n",
    "\n",
    "# MNIST total classes (0-9 digits)\n",
    "n_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#both placeholders are of type float\n",
    "x = tf.placeholder(\"float\", [None, 28,28,1])\n",
    "y = tf.placeholder(\"float\", [None, n_classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(x, W, b, strides=1):\n",
    "    # Conv2D wrapper, with bias and relu activation\n",
    "    x = tf.nn.conv2d(x, W, strides=[1, strides, strides, 1], padding='SAME')\n",
    "    x = tf.nn.bias_add(x, b)\n",
    "    return tf.nn.relu(x) \n",
    "\n",
    "def maxpool2d(x, k=2):\n",
    "    return tf.nn.max_pool(x, ksize=[1, k, k, 1], strides=[1, k, k, 1],padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Variable W0 already exists, disallowed. Did you mean to set reuse=True or reuse=tf.AUTO_REUSE in VarScope? Originally defined at:\n\n  File \"C:\\Users\\Alhassan\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1740, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n  File \"C:\\Users\\Alhassan\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3414, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\Alhassan\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-cd1c8b7d06c4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m weights = {\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[1;34m'wc1'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_variable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'W0'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitializer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxavier_initializer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[1;34m'wc2'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_variable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'W1'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitializer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxavier_initializer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;34m'wc3'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_variable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'W2'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitializer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxavier_initializer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;34m'wd1'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_variable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'W3'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitializer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxavier_initializer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[1;34m(name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint)\u001b[0m\n\u001b[0;32m   1326\u001b[0m       \u001b[0mpartitioner\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidate_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1327\u001b[0m       \u001b[0muse_resource\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_resource\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcustom_getter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcustom_getter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1328\u001b[1;33m       constraint=constraint)\n\u001b[0m\u001b[0;32m   1329\u001b[0m get_variable_or_local_docstring = (\n\u001b[0;32m   1330\u001b[0m     \"\"\"%s\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[1;34m(self, var_store, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint)\u001b[0m\n\u001b[0;32m   1088\u001b[0m           \u001b[0mpartitioner\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidate_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1089\u001b[0m           \u001b[0muse_resource\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_resource\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcustom_getter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcustom_getter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1090\u001b[1;33m           constraint=constraint)\n\u001b[0m\u001b[0;32m   1091\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1092\u001b[0m   def _get_partitioned_variable(self,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[1;34m(self, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint)\u001b[0m\n\u001b[0;32m    433\u001b[0m           \u001b[0mcaching_device\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcaching_device\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpartitioner\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m           \u001b[0mvalidate_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_resource\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_resource\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 435\u001b[1;33m           constraint=constraint)\n\u001b[0m\u001b[0;32m    436\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    437\u001b[0m   def _get_partitioned_variable(\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36m_true_getter\u001b[1;34m(name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, constraint)\u001b[0m\n\u001b[0;32m    402\u001b[0m           \u001b[0mtrainable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcollections\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcollections\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    403\u001b[0m           \u001b[0mcaching_device\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcaching_device\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidate_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 404\u001b[1;33m           use_resource=use_resource, constraint=constraint)\n\u001b[0m\u001b[0;32m    405\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    406\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcustom_getter\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36m_get_single_variable\u001b[1;34m(self, name, shape, dtype, initializer, regularizer, partition_info, reuse, trainable, collections, caching_device, validate_shape, use_resource, constraint)\u001b[0m\n\u001b[0;32m    741\u001b[0m                          \u001b[1;34m\"reuse=tf.AUTO_REUSE in VarScope? \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    742\u001b[0m                          \"Originally defined at:\\n\\n%s\" % (\n\u001b[1;32m--> 743\u001b[1;33m                              name, \"\".join(traceback.format_list(tb))))\n\u001b[0m\u001b[0;32m    744\u001b[0m       \u001b[0mfound_var\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_vars\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    745\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_compatible_with\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfound_var\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Variable W0 already exists, disallowed. Did you mean to set reuse=True or reuse=tf.AUTO_REUSE in VarScope? Originally defined at:\n\n  File \"C:\\Users\\Alhassan\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1740, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n  File \"C:\\Users\\Alhassan\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3414, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\Alhassan\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n"
     ]
    }
   ],
   "source": [
    "weights = {\n",
    "    'wc1': tf.get_variable('W0', shape=(3,3,1,32), initializer=tf.contrib.layers.xavier_initializer()), \n",
    "    'wc2': tf.get_variable('W1', shape=(3,3,32,64), initializer=tf.contrib.layers.xavier_initializer()), \n",
    "    'wc3': tf.get_variable('W2', shape=(3,3,64,128), initializer=tf.contrib.layers.xavier_initializer()), \n",
    "    'wd1': tf.get_variable('W3', shape=(4*4*128,128), initializer=tf.contrib.layers.xavier_initializer()), \n",
    "    'out': tf.get_variable('W6', shape=(128,n_classes), initializer=tf.contrib.layers.xavier_initializer()), \n",
    "}\n",
    "biases = {\n",
    "    'bc1': tf.get_variable('B0', shape=(32), initializer=tf.contrib.layers.xavier_initializer()),\n",
    "    'bc2': tf.get_variable('B1', shape=(64), initializer=tf.contrib.layers.xavier_initializer()),\n",
    "    'bc3': tf.get_variable('B2', shape=(128), initializer=tf.contrib.layers.xavier_initializer()),\n",
    "    'bd1': tf.get_variable('B3', shape=(128), initializer=tf.contrib.layers.xavier_initializer()),\n",
    "    'out': tf.get_variable('B4', shape=(10), initializer=tf.contrib.layers.xavier_initializer()),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_net(x, weights, biases):  \n",
    "\n",
    "    # here we call the conv2d function we had defined above and pass the input image x, weights wc1 and bias bc1.\n",
    "    conv1 = conv2d(x, weights['wc1'], biases['bc1'])\n",
    "    # Max Pooling (down-sampling), this chooses the max value from a 2*2 matrix window and outputs a 14*14 matrix.\n",
    "    conv1 = maxpool2d(conv1, k=2)\n",
    "\n",
    "    # Convolution Layer\n",
    "    # here we call the conv2d function we had defined above and pass the input image x, weights wc2 and bias bc2.\n",
    "    conv2 = conv2d(conv1, weights['wc2'], biases['bc2'])\n",
    "    # Max Pooling (down-sampling), this chooses the max value from a 2*2 matrix window and outputs a 7*7 matrix.\n",
    "    conv2 = maxpool2d(conv2, k=2)\n",
    "\n",
    "    conv3 = conv2d(conv2, weights['wc3'], biases['bc3'])\n",
    "    # Max Pooling (down-sampling), this chooses the max value from a 2*2 matrix window and outputs a 4*4.\n",
    "    conv3 = maxpool2d(conv3, k=2)\n",
    "\n",
    "\n",
    "    # Fully connected layer\n",
    "    # Reshape conv2 output to fit fully connected layer input\n",
    "    fc1 = tf.reshape(conv3, [-1, weights['wd1'].get_shape().as_list()[0]])\n",
    "    fc1 = tf.add(tf.matmul(fc1, weights['wd1']), biases['bd1'])\n",
    "    fc1 = tf.nn.relu(fc1)\n",
    "    # Output, class prediction\n",
    "    # finally we multiply the fully connected layer with the weights and add a bias term. \n",
    "    out = tf.add(tf.matmul(fc1, weights['out']), biases['out'])\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-18-989f812044df>:3: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See @{tf.nn.softmax_cross_entropy_with_logits_v2}.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = conv_net(x, weights, biases)\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y))\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here you check whether the index of the maximum value of the predicted image is equal to the actual labelled image. and both will be a column vector.\n",
    "correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "\n",
    "#calculate accuracy across all the given images and average them out. \n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot feed value of shape (16,) for Tensor 'Placeholder_1:0', which has shape '(?, 10)'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-a0a364cb2e15>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m                 \u001b[1;31m# Calculate batch loss and accuracy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m             opt = sess.run(optimizer, feed_dict={x: batch_x,\n\u001b[1;32m---> 15\u001b[1;33m                                                               y: batch_y})\n\u001b[0m\u001b[0;32m     16\u001b[0m             loss, acc = sess.run([cost, accuracy], feed_dict={x: batch_x,\n\u001b[0;32m     17\u001b[0m                                                               y: batch_y})\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    898\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 900\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    901\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1109\u001b[0m                              \u001b[1;34m'which has shape %r'\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1110\u001b[0m                              (np_val.shape, subfeed_t.name,\n\u001b[1;32m-> 1111\u001b[1;33m                               str(subfeed_t.get_shape())))\n\u001b[0m\u001b[0;32m   1112\u001b[0m           \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_feedable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1113\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Tensor %s may not be fed.'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0msubfeed_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot feed value of shape (16,) for Tensor 'Placeholder_1:0', which has shape '(?, 10)'"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init) \n",
    "    train_loss = []\n",
    "    test_loss = []\n",
    "    train_accuracy = []\n",
    "    test_accuracy = []\n",
    "    summary_writer = tf.summary.FileWriter('./Output', sess.graph)\n",
    "    for i in range(training_iters):\n",
    "        for batch in range(len(x_train)//batch_size):\n",
    "            batch_x = x_train[batch*batch_size:min((batch+1)*batch_size,len(x_train))]\n",
    "            batch_y = y_train[batch*batch_size:min((batch+1)*batch_size,len(y_train))]    \n",
    "            # Run optimization op (backprop).\n",
    "                # Calculate batch loss and accuracy\n",
    "            opt = sess.run(optimizer, feed_dict={x: batch_x,\n",
    "                                                              y: batch_y})\n",
    "            loss, acc = sess.run([cost, accuracy], feed_dict={x: batch_x,\n",
    "                                                              y: batch_y})\n",
    "        print(\"Iter \" + str(i) + \", Loss= \" + \\\n",
    "                      \"{:.6f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "                      \"{:.5f}\".format(acc))\n",
    "        print(\"Optimization Finished!\")\n",
    "\n",
    "        # Calculate accuracy for all 10000 mnist test images\n",
    "        test_acc,valid_loss = sess.run([accuracy,cost], feed_dict={x: x_test,y : y_test})\n",
    "        train_loss.append(loss)\n",
    "        test_loss.append(valid_loss)\n",
    "        train_accuracy.append(acc)\n",
    "        test_accuracy.append(test_acc)\n",
    "        print(\"Testing Accuracy:\",\"{:.5f}\".format(test_acc))\n",
    "    summary_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
