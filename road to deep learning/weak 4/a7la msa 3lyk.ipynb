{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "#from tensorflow.examples.tutorials.mnist import input_data\n",
    "%matplotlib inline\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-25-6e96f2f7aa15>, line 10)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-25-6e96f2f7aa15>\"\u001b[1;36m, line \u001b[1;32m10\u001b[0m\n\u001b[1;33m    data.append(img\u001b[0m\n\u001b[1;37m                   ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "img_dir = \"images/train/puppy\" # Enter Directory of all images \n",
    "data_path = os.path.join(img_dir,'*jpg')\n",
    "files = glob.glob(data_path)\n",
    "data = []\n",
    "for f1 in files:\n",
    "    img = cv2.imread(f1)\n",
    "    data.append(img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55000, 10)\n",
      "Training set (images) shape: (55000, 784)\n",
      "Training set (labels) shape: (55000, 10)\n",
      "Test set (images) shape: (10000, 784)\n",
      "Test set (labels) shape: (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(data.train.labels.shape)\n",
    "# Shapes of training set\n",
    "print(\"Training set (images) shape: {shape}\".format(shape=data.train.images.shape))\n",
    "print(\"Training set (labels) shape: {shape}\".format(shape=data.train.labels.shape))\n",
    "\n",
    "# Shapes of test set\n",
    "print(\"Test set (images) shape: {shape}\".format(shape=data.test.images.shape))\n",
    "print(\"Test set (labels) shape: {shape}\".format(shape=data.test.labels.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionary of target classes\n",
    "label_dict = {\n",
    " 0: 'T-shirt/top',\n",
    " 1: 'Trouser',\n",
    " 2: 'Pullover',\n",
    " 3: 'Dress',\n",
    " 4: 'Coat',\n",
    " 5: 'Sandal',\n",
    " 6: 'Shirt',\n",
    " 7: 'Sneaker',\n",
    " 8: 'Bag',\n",
    " 9: 'Ankle boot',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'(Label: Ankle boot)')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=[5,5])\n",
    "\n",
    "# Display the first image in training data\n",
    "plt.subplot(121)\n",
    "\n",
    "curr_img = np.reshape(data.train.images[30], (28,28))\n",
    "curr_lbl = np.argmax(data.train.labels[30,:])\n",
    "plt.imshow(curr_img)\n",
    "plt.title(\"(Label: \" + str(label_dict[curr_lbl]) + \")\")\n",
    "\n",
    "# Display the first image in testing data\n",
    "plt.subplot(122)\n",
    "curr_img = np.reshape(data.test.images[99], (28,28))\n",
    "curr_lbl = np.argmax(data.test.labels[99,:])\n",
    "print(curr_lbl)\n",
    "plt.imshow(curr_img, cmap='gray')\n",
    "plt.title(\"(Label: \" + str(label_dict[curr_lbl]) + \")\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.3803922 , 0.37647063, 0.3019608 ,\n",
       "       0.46274513, 0.2392157 , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.3529412 , 0.5411765 , 0.9215687 ,\n",
       "       0.9215687 , 0.9215687 , 0.9215687 , 0.9215687 , 0.9215687 ,\n",
       "       0.9843138 , 0.9843138 , 0.9725491 , 0.9960785 , 0.9607844 ,\n",
       "       0.9215687 , 0.74509805, 0.08235294, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.54901963,\n",
       "       0.9843138 , 0.9960785 , 0.9960785 , 0.9960785 , 0.9960785 ,\n",
       "       0.9960785 , 0.9960785 , 0.9960785 , 0.9960785 , 0.9960785 ,\n",
       "       0.9960785 , 0.9960785 , 0.9960785 , 0.9960785 , 0.9960785 ,\n",
       "       0.7411765 , 0.09019608, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.8862746 , 0.9960785 , 0.81568635,\n",
       "       0.7803922 , 0.7803922 , 0.7803922 , 0.7803922 , 0.54509807,\n",
       "       0.2392157 , 0.2392157 , 0.2392157 , 0.2392157 , 0.2392157 ,\n",
       "       0.5019608 , 0.8705883 , 0.9960785 , 0.9960785 , 0.7411765 ,\n",
       "       0.08235294, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.14901961, 0.32156864, 0.0509804 , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.13333334,\n",
       "       0.8352942 , 0.9960785 , 0.9960785 , 0.45098042, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.32941177, 0.9960785 ,\n",
       "       0.9960785 , 0.9176471 , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.32941177, 0.9960785 , 0.9960785 , 0.9176471 ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.4156863 , 0.6156863 ,\n",
       "       0.9960785 , 0.9960785 , 0.95294124, 0.20000002, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.09803922, 0.45882356, 0.8941177 , 0.8941177 ,\n",
       "       0.8941177 , 0.9921569 , 0.9960785 , 0.9960785 , 0.9960785 ,\n",
       "       0.9960785 , 0.94117653, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.26666668, 0.4666667 , 0.86274517,\n",
       "       0.9960785 , 0.9960785 , 0.9960785 , 0.9960785 , 0.9960785 ,\n",
       "       0.9960785 , 0.9960785 , 0.9960785 , 0.9960785 , 0.5568628 ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.14509805, 0.73333335,\n",
       "       0.9921569 , 0.9960785 , 0.9960785 , 0.9960785 , 0.8745099 ,\n",
       "       0.8078432 , 0.8078432 , 0.29411766, 0.26666668, 0.8431373 ,\n",
       "       0.9960785 , 0.9960785 , 0.45882356, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.4431373 , 0.8588236 , 0.9960785 , 0.9490197 , 0.89019614,\n",
       "       0.45098042, 0.34901962, 0.12156864, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.7843138 , 0.9960785 , 0.9450981 ,\n",
       "       0.16078432, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.6627451 , 0.9960785 ,\n",
       "       0.6901961 , 0.24313727, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.18823531,\n",
       "       0.9058824 , 0.9960785 , 0.9176471 , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.07058824, 0.48627454, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.32941177, 0.9960785 , 0.9960785 ,\n",
       "       0.6509804 , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.54509807, 0.9960785 , 0.9333334 , 0.22352943, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.8235295 , 0.9803922 , 0.9960785 ,\n",
       "       0.65882355, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.9490197 , 0.9960785 , 0.93725497, 0.22352943, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.34901962, 0.9843138 , 0.9450981 ,\n",
       "       0.3372549 , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.01960784,\n",
       "       0.8078432 , 0.96470594, 0.6156863 , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.01568628, 0.45882356, 0.27058825,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        ], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.train.images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9960785"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(data.train.images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(data.train.images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape training and testing image\n",
    "train_X = data.train.images.reshape(-1, 28, 28, 1)\n",
    "test_X = data.test.images.reshape(-1,28,28,1)\n",
    "train_X = train_X[0:7000]\n",
    "test_X = test_X[0:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7000, 28, 28, 1), (1000, 28, 28, 1))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.shape, test_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = data.train.labels\n",
    "test_y = data.test.labels\n",
    "train_y = train_y[0:7000]\n",
    "test_y = test_y[0:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7000, 10), (1000, 10))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.shape, test_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_iters = 12\n",
    "learning_rate = 0.01 \n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST data input (img shape: 28*28)\n",
    "n_input = 28\n",
    "\n",
    "# MNIST total classes (0-9 digits)\n",
    "n_classes = 10\n",
    "tf.reset_default_graph()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#both placeholders are of type float\n",
    "x = tf.placeholder(\"float\", [None, 28,28,1])\n",
    "y = tf.placeholder(\"float\", [None, n_classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(x, W, b, strides=1):\n",
    "    # Conv2D wrapper, with bias and relu activation\n",
    "    x = tf.nn.conv2d(x, W, strides=[1, strides, strides, 1], padding='SAME')\n",
    "    x = tf.nn.bias_add(x, b)\n",
    "    return tf.nn.relu(x) \n",
    "\n",
    "def maxpool2d(x, k=2):\n",
    "    return tf.nn.max_pool(x, ksize=[1, k, k, 1], strides=[1, k, k, 1],padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = {\n",
    "    'wc1': tf.get_variable('W0', shape=(3,3,1,32), initializer=tf.contrib.layers.xavier_initializer()), \n",
    "    'wc2': tf.get_variable('W1', shape=(3,3,32,64), initializer=tf.contrib.layers.xavier_initializer()), \n",
    "    'wc3': tf.get_variable('W2', shape=(3,3,64,128), initializer=tf.contrib.layers.xavier_initializer()), \n",
    "    'wd1': tf.get_variable('W3', shape=(4*4*128,128), initializer=tf.contrib.layers.xavier_initializer()), \n",
    "    'out': tf.get_variable('W6', shape=(128,n_classes), initializer=tf.contrib.layers.xavier_initializer()), \n",
    "}\n",
    "biases = {\n",
    "    'bc1': tf.get_variable('B0', shape=(32), initializer=tf.contrib.layers.xavier_initializer()),\n",
    "    'bc2': tf.get_variable('B1', shape=(64), initializer=tf.contrib.layers.xavier_initializer()),\n",
    "    'bc3': tf.get_variable('B2', shape=(128), initializer=tf.contrib.layers.xavier_initializer()),\n",
    "    'bd1': tf.get_variable('B3', shape=(128), initializer=tf.contrib.layers.xavier_initializer()),\n",
    "    'out': tf.get_variable('B4', shape=(10), initializer=tf.contrib.layers.xavier_initializer()),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_net(x, weights, biases):  \n",
    "\n",
    "    # here we call the conv2d function we had defined above and pass the input image x, weights wc1 and bias bc1.\n",
    "    conv1 = conv2d(x, weights['wc1'], biases['bc1'])\n",
    "    # Max Pooling (down-sampling), this chooses the max value from a 2*2 matrix window and outputs a 14*14 matrix.\n",
    "    conv1 = maxpool2d(conv1, k=2)\n",
    "\n",
    "    # Convolution Layer\n",
    "    # here we call the conv2d function we had defined above and pass the input image x, weights wc2 and bias bc2.\n",
    "    conv2 = conv2d(conv1, weights['wc2'], biases['bc2'])\n",
    "    # Max Pooling (down-sampling), this chooses the max value from a 2*2 matrix window and outputs a 7*7 matrix.\n",
    "    conv2 = maxpool2d(conv2, k=2)\n",
    "\n",
    "    conv3 = conv2d(conv2, weights['wc3'], biases['bc3'])\n",
    "    # Max Pooling (down-sampling), this chooses the max value from a 2*2 matrix window and outputs a 4*4.\n",
    "    conv3 = maxpool2d(conv3, k=2)\n",
    "\n",
    "\n",
    "    # Fully connected layer\n",
    "    # Reshape conv2 output to fit fully connected layer input\n",
    "    fc1 = tf.reshape(conv3, [-1, weights['wd1'].get_shape().as_list()[0]])\n",
    "    fc1 = tf.add(tf.matmul(fc1, weights['wd1']), biases['bd1'])\n",
    "    fc1 = tf.nn.relu(fc1)\n",
    "    # Output, class prediction\n",
    "    # finally we multiply the fully connected layer with the weights and add a bias term. \n",
    "    out = tf.add(tf.matmul(fc1, weights['out']), biases['out'])\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-23-989f812044df>:3: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See @{tf.nn.softmax_cross_entropy_with_logits_v2}.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = conv_net(x, weights, biases)\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y))\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here you check whether the index of the maximum value of the predicted image is equal to the actual labelled image. and both will be a column vector.\n",
    "correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "\n",
    "#calculate accuracy across all the given images and average them out. \n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0, Loss= 0.332909, Training Accuracy= 0.87500\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.90600\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-6137a5f61180>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m                 \u001b[1;31m# Calculate batch loss and accuracy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m             opt = sess.run(optimizer, feed_dict={x: batch_x,\n\u001b[1;32m---> 15\u001b[1;33m                                                               y: batch_y})\n\u001b[0m\u001b[0;32m     16\u001b[0m             loss, acc = sess.run([cost, accuracy], feed_dict={x: batch_x,\n\u001b[0;32m     17\u001b[0m                                                               y: batch_y})\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    898\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 900\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    901\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1133\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1135\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1136\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1314\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1316\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1317\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1320\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1321\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1322\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1323\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1324\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1305\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1307\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1309\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1407\u001b[0m       return tf_session.TF_SessionRun_wrapper(\n\u001b[0;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1409\u001b[1;33m           run_metadata)\n\u001b[0m\u001b[0;32m   1410\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1411\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init) \n",
    "    train_loss = []\n",
    "    test_loss = []\n",
    "    train_accuracy = []\n",
    "    test_accuracy = []\n",
    "    summary_writer = tf.summary.FileWriter('./Output', sess.graph)\n",
    "    for i in range(training_iters):\n",
    "        for batch in range(len(train_X)//batch_size):\n",
    "            batch_x = train_X[batch*batch_size:min((batch+1)*batch_size,len(train_X))]\n",
    "            batch_y = train_y[batch*batch_size:min((batch+1)*batch_size,len(train_y))]    \n",
    "            # Run optimization op (backprop).\n",
    "                # Calculate batch loss and accuracy\n",
    "            opt = sess.run(optimizer, feed_dict={x: batch_x,\n",
    "                                                              y: batch_y})\n",
    "            loss, acc = sess.run([cost, accuracy], feed_dict={x: batch_x,\n",
    "                                                              y: batch_y})\n",
    "        print(\"Iter \" + str(i) + \", Loss= \" + \\\n",
    "                      \"{:.6f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "                      \"{:.5f}\".format(acc))\n",
    "        print(\"Optimization Finished!\")\n",
    "\n",
    "        # Calculate accuracy for all 10000 mnist test images\n",
    "        test_acc,valid_loss = sess.run([accuracy,cost], feed_dict={x: test_X,y : test_y})\n",
    "        train_loss.append(loss)\n",
    "        test_loss.append(valid_loss)\n",
    "        train_accuracy.append(acc)\n",
    "        test_accuracy.append(test_acc)\n",
    "        print(\"Testing Accuracy:\",\"{:.5f}\".format(test_acc))\n",
    "    summary_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
